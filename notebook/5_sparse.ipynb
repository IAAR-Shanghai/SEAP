{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/5_sparse.ipynb\n",
    "\n",
    "import sys\n",
    "import gc\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "project_root = os.path.abspath(\"..\")\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.data_utils import load_datasets, extract_inputs_and_labels\n",
    "from src.model_utils import load_model_and_tokenizer\n",
    "\n",
    "from src.activations import (\n",
    "    load_activations, \n",
    "    load_weight_l2_info\n",
    ")\n",
    "\n",
    "from src.pruning_utils.compute_scores import compute_all_layers_scores\n",
    "from src.pruning_utils.generate_masks import (\n",
    "    generate_masks_for_all_layers,\n",
    "    save_masks_to_file,\n",
    "    compute_layerwise_sparsity\n",
    ")\n",
    "from src.pruning_utils.apply_pruning import apply_pruning_to_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Llama-2-7b-hf\"\n",
    "MODELS_ROOT_PATH = \"/mnt/data102_d2/huggingface/models\"\n",
    "ACTIVATIONS_ROOT_PATH = '../activations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "METHOD = \"WIFV\"        # compute_scores时使用的方法 (IFV, WIFV, WIFN, VAR, MEAN)\n",
    "STRUCTURE = \"AL-AM\"    # 生成mask时使用的结构策略\n",
    "PRUNING_RATIO = 0.1    # 剪枝比例\n",
    "REMOVE_HEADS = 1       # 如果STRUCTURE在需要固定移除heads的场景才会用到\n",
    "GLOBAL_PRUNING = False # 是否跨层做全局排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 应用剪枝相关参数\n",
    "USE_BIAS_COMPENSATION = False  # 是否进行Bias补偿\n",
    "UNSTRUCTURED_MASK = True       # True表示只mask不真正删除(soft mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试随机数种子\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(MODELS_ROOT_PATH, MODEL_NAME)\n",
    "model, tokenizer = load_model_and_tokenizer(model_path)\n",
    "model.eval().to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.layers[1].self_attn.o_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_path = os.path.join(ACTIVATIONS_ROOT_PATH, MODEL_NAME)\n",
    "activation_data_dict = load_activations(activations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里假设选择其中某个任务 (比如 'gsm8k') 的激活数据，如果你有多个任务，可以合并或挑选\n",
    "TASK_KEY = 'gsm8k'\n",
    "activation_data = activation_data_dict[TASK_KEY]  # 形如：{layer_idx: {...}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(activation_data[0]['mlp_input_states']['l2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载权重L2信息\n",
    "weight_l2_path = os.path.join(activations_path, 'weight_l2_info.pt')\n",
    "weight_l2_data = load_weight_l2_info(weight_l2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- 检查激活信息的结构 --------------\n",
    "sample_layer_idx = 0\n",
    "mlp_var = activation_data[sample_layer_idx][\"mlp_intermediate_states\"].get(\"var\", None)\n",
    "print(f\"Layer {sample_layer_idx} mlp_intermediate_states.var shape = {mlp_var.shape if mlp_var is not None else None}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- 准备模型的关键信息 --------------\n",
    "num_layers = model.config.num_hidden_layers\n",
    "hidden_size = model.config.hidden_size\n",
    "num_heads = model.config.num_attention_heads\n",
    "intermediate_size = model.config.intermediate_size  # 通常是 4 * hidden_size\n",
    "print(f\"num_layers={num_layers}, hidden_size={hidden_size}, num_heads={num_heads}, intermediate_size={intermediate_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- 计算剪枝分数 (Compute Scores) --------------\n",
    "scores_dict = compute_all_layers_scores(\n",
    "    activation_data=activation_data,\n",
    "    weight_data=weight_l2_data,\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    num_heads=num_heads,\n",
    "    intermediate_size=intermediate_size,\n",
    "    method=METHOD  # 这里用 WIFV\n",
    ")\n",
    "\n",
    "print(f\"Computed scores_dict with method={METHOD}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以查看某层的分数\n",
    "for layer_idx in range(min(2, num_layers)):  # 打印前2层看看\n",
    "    attn_scores = scores_dict[layer_idx][\"attn_scores\"]\n",
    "    mlp_scores = scores_dict[layer_idx][\"mlp_scores\"]\n",
    "    print(f\"\\nLayer {layer_idx}: attn_scores shape={attn_scores.shape}, mlp_scores shape={mlp_scores.shape}\")\n",
    "    print(f\"  attn_scores[:5] = {attn_scores[:5]}\")\n",
    "    print(f\"  mlp_scores[:5]  = {mlp_scores[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- 生成 Mask (Generate Masks) --------------\n",
    "attn_masks, mlp_masks = generate_masks_for_all_layers(\n",
    "    scores_dict=scores_dict,\n",
    "    structure=STRUCTURE,\n",
    "    pruning_ratio=PRUNING_RATIO,\n",
    "    hidden_size=hidden_size,   # AL-AM 需要\n",
    "    num_heads=num_heads        # AL-AM 需要\n",
    ")\n",
    "\n",
    "print(f\"Generated masks with structure={STRUCTURE}, pruning_ratio={PRUNING_RATIO}, remove_heads={REMOVE_HEADS}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印一些mask信息\n",
    "for layer_idx in range(min(2, num_layers)):\n",
    "    a_mask = attn_masks[layer_idx]\n",
    "    m_mask = mlp_masks[layer_idx]\n",
    "    print(f\"Layer {layer_idx}: \"\n",
    "          f\"attn_mask.sum() = {a_mask.sum().item()} / {len(a_mask)}, \"\n",
    "          f\"mlp_mask.sum() = {m_mask.sum().item()} / {len(m_mask)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsities = compute_layerwise_sparsity(attn_masks, mlp_masks)\n",
    "for layer_idx, data in sparsities.items():\n",
    "    print(f\"Layer {layer_idx}: attn_sparsity={data['attn_sparsity']:.3f}, \"\n",
    "        f\"mlp_sparsity={data['mlp_sparsity']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- 应用剪枝 (Apply Pruning) --------------\n",
    "apply_pruning_to_model(\n",
    "    model=model,\n",
    "    attn_masks=attn_masks,\n",
    "    mlp_masks=mlp_masks,\n",
    "    attn_mean_inps=None,   # 如果你有 baseline_inp，可传dict\n",
    "    mlp_mean_inps=None,    # 同理\n",
    "    device=\"cuda\",\n",
    "    bias=USE_BIAS_COMPENSATION,\n",
    "    unstr=UNSTRUCTURED_MASK,\n",
    "    head_dim=hidden_size // num_heads\n",
    ")\n",
    "\n",
    "print(f\"Pruning applied. [bias={USE_BIAS_COMPENSATION}, unstr={UNSTRUCTURED_MASK}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
